{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The War on Spam Text Messages\n",
    "We all ___hate___ spam texts. It seems around election time the amount of spam texts skyrockets. Although this filter might not perform perfectly against the political campaigning texts, a few tweaks and additional data could potentially help filter those out too.  \n",
    "Using a Naive Bayes algorithm we are going to build a spam filter for SMS text messages.  \n",
    "The human classifications are in the data set for the SMS messages. These will be used for training, and checking the accuracy of the filter. (The classification of 'ham' indicates a non-spam message)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "msgs = pd.read_csv('SMSSpamCollection.txt', sep='\\t', header=None, names=['label', 'SMS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>SMS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5572</td>\n",
       "      <td>5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>5169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>ham</td>\n",
       "      <td>Sorry, I'll call later</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4825</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       label                     SMS\n",
       "count   5572                    5572\n",
       "unique     2                    5169\n",
       "top      ham  Sorry, I'll call later\n",
       "freq    4825                      30"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msgs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataframe into 2 dataframes a training set and a testing set.\n",
    "train = msgs.sample(frac=.8, random_state=1)\n",
    "test = msgs.drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resetting both indexes.\n",
    "train = train.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ham vs Spam percentages of each dataframe\n",
      "Training:\n",
      "ham     86.54105\n",
      "spam    13.45895\n",
      "Name: label, dtype: float64\n",
      "Testing:\n",
      "ham     86.804309\n",
      "spam    13.195691\n",
      "Name: label, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('Ham vs Spam percentages of each dataframe')\n",
    "print('Training:')\n",
    "print(train['label'].value_counts(normalize=True)*100)\n",
    "print('Testing:')\n",
    "print(test['label'].value_counts(normalize=True)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning up the data\n",
    "train['SMS'] = train['SMS'].str.replace(r'\\W', ' ').str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Vocabulary for the Naive Bayes Algorithm\n",
    "Here we extract every word out of the text messages in the training data set. The `vocab` is then turned into a `set()` to remove any duplicate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['SMS'] = train['SMS'].str.split()\n",
    "vocab = []\n",
    "for row in train['SMS']:\n",
    "    for word in row:\n",
    "        vocab.append(word)\n",
    "\n",
    "vocab = set(vocab)\n",
    "vocab = list(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnt_per_sms = {word: [0] * len(train['SMS']) for word in vocab}\n",
    "for i, sms in enumerate(train['SMS']):\n",
    "    for word in sms:\n",
    "        word_cnt_per_sms[word][i] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cnts_df = pd.DataFrame(data=word_cnt_per_sms)\n",
    "train_df = pd.concat([train, word_cnts_df], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating the probabilities for each word in both the spam and ham classed messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = train_df['label'].value_counts(normalize=True)[1]\n",
    "p_ham = train_df['label'].value_counts(normalize=True)[0]\n",
    "\n",
    "n_spam = train_df[train_df['label'] == 'spam'].iloc[:,2:].sum(axis=1)\n",
    "n_ham = train_df[train_df['label'] ==  'ham'].iloc[:,2:].sum(axis=1)\n",
    "\n",
    "n_spam = n_spam.sum()\n",
    "n_ham = n_ham.sum()\n",
    "n_vocab = train_df.shape[1] - 2\n",
    "# Changing alpha to 0.6 actually increased the accuracy a bit (0.1%)\n",
    "# alpha removes the 0 probability for words not in the vocabulary\n",
    "alpha = .6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spam_params = {w: [0] for w in vocab}\n",
    "ham_params = {w: [0] for w in vocab}\n",
    "spam_msgs =  train_df[train_df['label']=='spam']\n",
    "ham_msgs = train_df[train_df['label']=='ham']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in spam_params:\n",
    "    spam_params[k] = (spam_msgs[k].sum() + alpha)/(n_spam + alpha*n_vocab)\n",
    "for k in ham_params:\n",
    "    ham_params[k] = (ham_msgs[k].sum() + alpha)/(n_ham + alpha*n_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The classify function which checks a message against the training data set.\n",
    "By iterating through each word in the message it checks the probability of a word belonging to the spam or ham separated sets of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spam'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classification function\n",
    "def classify(message):\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_msg = p_spam\n",
    "    p_ham_given_msg = p_ham\n",
    "    \n",
    "    label = 'ham'\n",
    "    \n",
    "    for word in message:\n",
    "        if word in spam_params:\n",
    "            p_spam_given_msg *= spam_params[word]\n",
    "        if word in ham_params:\n",
    "            p_ham_given_msg *= ham_params[word]\n",
    "    if p_spam_given_msg > p_ham_given_msg:\n",
    "        label = 'spam'\n",
    "    if p_spam_given_msg == p_ham_given_msg:\n",
    "        print('Probabilities are equal, assigning to ham')\n",
    "        \n",
    "    # if the probabilities are equal err on the side of ham\n",
    "    #if p_spam_given_msg == p_ham_given_msg:\n",
    "        #label = 'ham'\n",
    "    return label\n",
    "\n",
    "classify('winner free money')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities are equal, assigning to ham\n"
     ]
    }
   ],
   "source": [
    "test['prediction'] = test['SMS'].apply(classify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we will calculate the accuracy of our filter against the human classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct: 1102\n",
      "Failed: 12\n",
      "Accuracy: 98.92%\n"
     ]
    }
   ],
   "source": [
    "correct, fail = 0, 0\n",
    "total = test.shape[0]\n",
    "index_failed = []\n",
    "for row in test.iterrows():\n",
    "    row  = row[1]\n",
    "    if row['label'] == row['prediction']:\n",
    "        correct += 1\n",
    "    else:\n",
    "        fail += 1\n",
    "        index_failed.append(row)\n",
    "        \n",
    "print(f'Correct: {correct}')\n",
    "print(f'Failed: {fail}')\n",
    "print(f'Accuracy: {correct/total*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 98.92% Accuracy\n",
    "The spam filter correctly classified 98.92% of the test data set. Using the assumption that if a message's probability of spam is equal to it's probability of ham, we classified it as ham. It correctly eliminated 1 failed occurrence in our test messages, there were 6 occurrences when the algorithm is ran on the entire data set (see last cell). All of the messages classified as ham due to the equal probabilities were predicted correctly. Another slight tweak was adjusting the alpha value. Changing it to 0.6 instead of 1 improved our accuracy some as well.  \n",
    "  \n",
    "Out of the 12 failed classifications 7 spam messages would have made it through our filter, and 5 ham messages would have been filtered (or classified as spam) erroneously.  \n",
    "  \n",
    "When running the filter on the entire data set we were 99.30% accurate. The Naive Bayes algorithm was quite effective at calculating the probability of spam messages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------\n",
      "No calls..messages..missed calls\n",
      "prediction: spam\n",
      "label: ham\n",
      "--------------\n",
      "Hello. We need some posh birds and chaps to user trial prods for champneys. Can i put you down? I need your address and dob asap. Ta r\n",
      "prediction: ham\n",
      "label: spam\n",
      "--------------\n",
      "26th OF JULY\n",
      "prediction: spam\n",
      "label: ham\n",
      "--------------\n",
      "0A$NETWORKS allow companies to bill for SMS, so they are responsible for their \"suppliers\", just as a shop has to give a guarantee on what they sell. B. G.\n",
      "prediction: ham\n",
      "label: spam\n",
      "--------------\n",
      "RCT' THNQ Adrian for U text. Rgds Vatian\n",
      "prediction: ham\n",
      "label: spam\n",
      "--------------\n",
      "Not heard from U4 a while. Call me now am here all night with just my knickers on. Make me beg for it like U did last time 01223585236 XX Luv Nikiyu4.net\n",
      "prediction: ham\n",
      "label: spam\n",
      "--------------\n",
      "2/2 146tf150p\n",
      "prediction: ham\n",
      "label: spam\n",
      "--------------\n",
      "Oh my god! I've found your number again! I'm so glad, text me back xafter this msgs cst std ntwk chg £1.50\n",
      "prediction: ham\n",
      "label: spam\n",
      "--------------\n",
      "Unlimited texts. Limited minutes.\n",
      "prediction: spam\n",
      "label: ham\n",
      "--------------\n",
      "Hi babe its Chloe, how r u? I was smashed on saturday night, it was great! How was your weekend? U been missing me? SP visionsms.com Text stop to stop 150p/text\n",
      "prediction: ham\n",
      "label: spam\n",
      "--------------\n",
      "Nokia phone is lovly..\n",
      "prediction: spam\n",
      "label: ham\n",
      "--------------\n",
      "We have sent JD for Customer Service cum Accounts Executive to ur mail id, For details contact us\n",
      "prediction: spam\n",
      "label: ham\n"
     ]
    }
   ],
   "source": [
    "for i in index_failed:\n",
    "    print('--------------')\n",
    "    print(i['SMS'])\n",
    "    print('prediction:', i['prediction'])\n",
    "    print('label:', i['label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function returns more details pertaining to a particular message\n",
    "# It returns the relative probabilities and the difference between the two.\n",
    "def reclass_check(message, tie_ham=True):\n",
    "    message = re.sub(r'\\W', ' ', message)\n",
    "    message = message.lower().split()\n",
    "    \n",
    "    p_spam_given_msg = p_spam\n",
    "    p_ham_given_msg = p_ham\n",
    "    \n",
    "    label = 'ham'\n",
    "    \n",
    "    for word in message:\n",
    "        if word in spam_params:\n",
    "            p_spam_given_msg *= spam_params[word]\n",
    "        if word in ham_params:\n",
    "            p_ham_given_msg *= ham_params[word]\n",
    "    if p_spam_given_msg > p_ham_given_msg:\n",
    "        label = 'spam'\n",
    "    if not tie_ham:\n",
    "        if p_spam_given_msg == p_ham_given_msg:\n",
    "            label = 'not sure'\n",
    "    return label, p_ham_given_msg, p_spam_given_msg, (p_ham_given_msg - p_spam_given_msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('spam', 3.3337319614499942e-18, 1.546878343065051e-17, -1.2135051469200517e-17)\n",
      "('ham', 3.8459433558699016e-61, 1.053234146087431e-70, 3.8459433548166676e-61)\n",
      "('spam', 5.496785842777343e-13, 5.6897472274736865e-12, -5.140068643195952e-12)\n",
      "('ham', 1.4401616339935071e-68, 1.9018184774337135e-71, 1.4382598155160735e-68)\n",
      "('ham', 6.759560064531696e-08, 3.201537848985072e-08, 3.5580222155466237e-08)\n",
      "('ham', 1.9674023341509878e-84, 2.285903402623665e-93, 1.9674023318650843e-84)\n",
      "('ham', 1.5571659241445183e-05, 9.357979941924251e-06, 6.213679299520932e-06)\n",
      "('ham', 1.2991774226844665e-66, 4.1413736950670494e-73, 1.299177008547097e-66)\n",
      "('spam', 1.3047315846592374e-12, 1.4113300331928352e-11, -1.2808568747269115e-11)\n",
      "('ham', 3.980373812097504e-95, 4.591967501563511e-99, 3.979914615347347e-95)\n",
      "('spam', 3.3310522207230706e-10, 4.8964901798375424e-09, -4.563384957765235e-09)\n",
      "('spam', 1.1565730001971696e-60, 3.593766741311431e-58, -3.58220101130946e-58)\n"
     ]
    }
   ],
   "source": [
    "# to check if defaulting to ham if tied we can run the reclass_check to see if any of the values are 0\n",
    "# which they are not for both the testing set and the entire data set (not displayed),\n",
    "# but you can try it out if you put this code in a cell below the last cell.\n",
    "for i in index_failed:\n",
    "    print(reclass_check(i['SMS']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And this is how it performs against the entire data set (both the testing and training sets combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilities are equal, assigning to ham\n",
      "Probabilities are equal, assigning to ham\n",
      "Probabilities are equal, assigning to ham\n",
      "Probabilities are equal, assigning to ham\n",
      "Probabilities are equal, assigning to ham\n",
      "Probabilities are equal, assigning to ham\n",
      "Probabilities are equal, assigning to ham\n"
     ]
    }
   ],
   "source": [
    "msgs['prediction'] = msgs['SMS'].apply(classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the entire data set (test and train sets):\n",
      "correct: 5533\n",
      "failed: 39\n",
      "Accuracy: 99.30%\n"
     ]
    }
   ],
   "source": [
    "correct, fail = 0, 0\n",
    "total = msgs.shape[0]\n",
    "index_failed = []\n",
    "for row in msgs.iterrows():\n",
    "    row  = row[1]\n",
    "    if row['label'] == row['prediction']:\n",
    "        correct += 1\n",
    "    else:\n",
    "        fail += 1\n",
    "        index_failed.append(row)\n",
    "print('For the entire data set (test and train sets):')       \n",
    "print(f'correct: {correct}')\n",
    "print(f'failed: {fail}')\n",
    "print(f'Accuracy: {correct/total*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Not too shabby!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
